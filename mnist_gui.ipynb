{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import tkinter as tk\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx as onnx\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageTk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pathlib import Path\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Neural Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and test data loader for MNIST\n",
    "training_data = torchvision.datasets.MNIST(\n",
    "    '/files/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                              torchvision.transforms.Normalize((0.1307,), (0.3081,))]\n",
    "                                             )\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            ])),\n",
    "        batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x27703442de0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setup numerous variables for training and testing\n",
    "train_dataloader = DataLoader(training_data, 64, shuffle=True)\n",
    "epochs = 3\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "batch_size = 64\n",
    "\n",
    "#Creates a random seed\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use a pretrained model\n",
    "pretrained_model = \"model_weights.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sets up Epsilons to run through for testing\n",
    "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
    "use_cuda=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  False\n"
     ]
    }
   ],
   "source": [
    "#Attempts to use cuda if available\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "# Initialize the network\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(pretrained_model))\n",
    "model2 = Net().to(device)\n",
    "\n",
    "#Creates loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM attack code\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # Return the perturbed image\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tests neural network on FGSM of various epsilons and saves images\n",
    "def test(model, device, test_loader, epsilon):\n",
    "\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    for data, target in test_loader:\n",
    "\n",
    "        # Send the data and label to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        output = model(data)\n",
    "        # get the index of the max log-probability\n",
    "        init_pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # Zero all existing gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Calculate gradients of model in backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect datagrad\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        # Call FGSM Attack\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "\n",
    "        # Re-classify the perturbed image\n",
    "        output = model(perturbed_data)\n",
    "\n",
    "\n",
    "        # get the index of the max log-probability\n",
    "        final_pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "        #Save images for examples in gui\n",
    "        examples = []\n",
    "        if len(examples) < 500:\n",
    "            ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "            examples.append(\n",
    "                    (init_pred.item(), final_pred.item(), ex))\n",
    "        \n",
    "\n",
    "        # Check for success\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            # Special case for saving 0 epsilon examples\n",
    "            if (epsilon == 0) and (len(adv_examples) < 50):\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append(\n",
    "                    (init_pred.item(), final_pred.item(), adv_ex))\n",
    "        else:\n",
    "            # Save some adv examples for visualization later\n",
    "            if len(adv_examples) < 500:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append(\n",
    "                    (init_pred.item(), final_pred.item(), adv_ex))\n",
    "\n",
    "    # Calculate final accuracy for this epsilon\n",
    "    final_acc = correct/float(len(test_loader))\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon,\n",
    "          correct, len(test_loader), final_acc))\n",
    "\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, examples, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0\tTest Accuracy = 9871 / 10000 = 0.9871\n",
      "Epsilon: 0.05\tTest Accuracy = 9410 / 10000 = 0.941\n",
      "Epsilon: 0.1\tTest Accuracy = 8321 / 10000 = 0.8321\n",
      "Epsilon: 0.15\tTest Accuracy = 6446 / 10000 = 0.6446\n",
      "Epsilon: 0.2\tTest Accuracy = 4215 / 10000 = 0.4215\n",
      "Epsilon: 0.25\tTest Accuracy = 2330 / 10000 = 0.233\n",
      "Epsilon: 0.3\tTest Accuracy = 1072 / 10000 = 0.1072\n"
     ]
    }
   ],
   "source": [
    "#Sets model to evaluation and creates arrays for images to be saved to\n",
    "accuracies = []\n",
    "examples = []\n",
    "misclassified_examples = []\n",
    "model.eval()\n",
    "\n",
    "#Run test for each epsilon\n",
    "for eps in epsilons:\n",
    "    acc, ex, misEx = test(model, device, test_loader, eps)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)\n",
    "    misclassified_examples.append(misEx)\n",
    "\n",
    "#Saves each epsilon to a different variable. This probably should be changed for readability\n",
    "example0, example0_05, example0_1, example0_15, example0_2, example0_25, example0_3 = examples;\n",
    "misclassified0, misclassified0_05, misclassified0_1, misclassified0_15, misclassified0_2, misclassified0_25, misclassified0_3 = misclassified_examples;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Initializes an image for GUI\n",
    "label, new_label, image, = misclassified0_15[0]\n",
    "plt.title(\"What is this number?\")\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.savefig('saved_figure.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates an image of epsilon 0.2\n",
    "def generateNewImage(count):\n",
    "    label, new_label, image, = misclassified0_15[count]\n",
    "    plt.title(\"What is this number?\")\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.savefig('saved_figure2.png')\n",
    "    return label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializes the height and width of image for GUI\n",
    "HEIGHT = 200\n",
    "WIDTH = 200\n",
    "IMAGE_HEIGHT = 200\n",
    "IMAGE_WIDTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables initialized for my user path. Can be changed for different user\n",
    "x = \"/Users/Alex Vogt/Desktop/work-visualization/MNIST_Alex/saved_figure.png\" \n",
    "x2 = \"/Users/Alex Vogt/Desktop/work-visualization/MNIST_Alex/saved_figure2.png\" \n",
    "x3 = \"/Users/Alex Vogt/Desktop/work-visualization/MNIST_Alex/saved_figure3.png\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count of image displayed currently and count guessed correctly in the GUI\n",
    "correctCount = 0\n",
    "totalCount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to display perturbed images for user based on user input\n",
    "def numClick():\n",
    "    currNum = a.get()\n",
    "    temp = 0\n",
    "    # curr = len(d) - 1\n",
    "    curr = 499\n",
    "    images = []\n",
    "    while temp < 6 and curr > 0:\n",
    "        label, new_label, image = misclassified0_15[curr]\n",
    "        if label == int(currNum):\n",
    "            images.append(image)\n",
    "            temp = temp + 1\n",
    "        curr = curr - 1\n",
    "    \n",
    "    for currIterator in range(6):\n",
    "        currImage = images[currIterator]\n",
    "        plt.imshow(currImage, cmap=\"gray\")\n",
    "        plt.savefig('saved_figure3.png')\n",
    "\n",
    "        image1 = Image.open(x3)\n",
    "        test = ImageTk.PhotoImage(image1)\n",
    "        label1 = tk.Label(number_frame, image=test)\n",
    "        label1.image = test\n",
    "        if currIterator < 3:\n",
    "            label1.grid(row=3, column=currIterator, sticky=\"nsew\", padx=2, pady=2)\n",
    "        else:\n",
    "            label1.grid(row=4, column=(currIterator - 3), sticky=\"nsew\", padx=2, pady=2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for button for user guess\n",
    "def myClick():\n",
    "    global totalCount\n",
    "    global label\n",
    "    currCount = correctCount\n",
    "    newLabel = label\n",
    "    currNum = e.get()\n",
    "    if (int(currNum) == newLabel):\n",
    "        currCount = currCount + 1\n",
    "        myLabel = Label(output_frame, text=\"Correct!\")\n",
    "        myLabel.grid(row=0, column=2, rowspan=2, sticky=\"nsew\", padx=2, pady=2)\n",
    "    else: \n",
    "        myLabel2 = Label(output_frame, text=\"Incorrect\")\n",
    "        myLabel2.grid(row=0, column=2, rowspan=2, sticky=\"nsew\", padx=2, pady=2)\n",
    "    #Create new image\n",
    "    label = generateNewImage(totalCount)\n",
    "    image1 = Image.open(x2)\n",
    "    test = ImageTk.PhotoImage(image1)\n",
    "    label1 = tk.Label(image_frame, image=test)\n",
    "    label1.image = test\n",
    "    label1.grid(row=0, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "    #Generates new model prediction\n",
    "    stringModel = \"Model Prediction: \"\n",
    "    ga, answer, gar, = misclassified0_15[totalCount]\n",
    "    convAnswer = str(answer)\n",
    "    stringModel = stringModel + convAnswer\n",
    "    def_label = tk.Label(visual_aid_frame, text=stringModel)\n",
    "    def_label.pack(padx=10, pady=5, fill=tk.BOTH)\n",
    "    \n",
    "    #Label(image_frame, image=test).grid(row=1, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "    totalCount = totalCount + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyimage53\n"
     ]
    },
    {
     "ename": "TclError",
     "evalue": "image \"pyimage53\" doesn't exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-5d467335218b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageTk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPhotoImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mLabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msticky\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"nsew\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpady\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, cnf, **kw)\u001b[0m\n\u001b[0;32m   2758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2759\u001b[0m         \"\"\"\n\u001b[1;32m-> 2760\u001b[1;33m         \u001b[0mWidget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'label'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2762\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mListbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWidget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXView\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYView\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, widgetName, cnf, kw, extra)\u001b[0m\n\u001b[0;32m   2291\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mcnf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2292\u001b[0m         self.tk.call(\n\u001b[1;32m-> 2293\u001b[1;33m             (widgetName, self._w) + extra + self._options(cnf))\n\u001b[0m\u001b[0;32m   2294\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2295\u001b[0m             \u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTclError\u001b[0m: image \"pyimage53\" doesn't exist"
     ]
    }
   ],
   "source": [
    "#GUI\n",
    "root = Tk()\n",
    "root.title(\"Human Testing of Adversarial Training\")\n",
    "\n",
    "#Setup frames\n",
    "# global image_frame\n",
    "image_frame = tk.Frame(root, background=\"#FFF0C1\", bd=1, relief=\"sunken\")\n",
    "input_frame = tk.Frame(root, background=\"#D2E2FB\", bd=1, relief=\"sunken\")\n",
    "visual_aid_frame = tk.Frame(root, background=\"#CCE4CA\", bd=1, relief=\"sunken\")\n",
    "output_frame = tk.Frame(root, background=\"#F5C2C1\", bd=1, relief=\"sunken\")\n",
    "number_frame = tk.Frame(root, background=\"#0000FF.\", bd=1, relief=\"sunken\")\n",
    "image_frame.grid(row=0, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "input_frame.grid(row=1, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "visual_aid_frame.grid(row=0, column=1, rowspan=2, sticky=\"nsew\", padx=2, pady=2)\n",
    "output_frame.grid(row=0, column=2, rowspan=2, sticky=\"nsew\", padx=2, pady=2)\n",
    "number_frame.grid(row=0, column=3, rowspan=2, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "\n",
    "#Configure frames\n",
    "root.grid_rowconfigure(0, weight=3)\n",
    "root.grid_rowconfigure(1, weight=2)\n",
    "root.grid_columnconfigure(0, weight=3)\n",
    "root.grid_columnconfigure(1, weight=2)\n",
    "root.grid_columnconfigure(2, weight=2)\n",
    "root.grid_columnconfigure(3, weight=2)\n",
    "\n",
    "\n",
    "# Create a photoimage object of the image in the path\n",
    "image1 = Image.open(x)\n",
    "test = ImageTk.PhotoImage(image1)\n",
    "print(test)\n",
    "Label(image_frame, image=test).grid(row=0, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "\n",
    "#Creates entry box for user guess\n",
    "e = Entry(input_frame, width=50)\n",
    "e.grid(row=0, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "\n",
    "#Adds a Button\n",
    "myButton = Button(input_frame, text=\"Click Me!\", pady=50, command=partial(myClick))\n",
    "myButton.grid(row=1, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "#Visual Aid\n",
    "stringModel = \"Model Prediction: \"\n",
    "ga, answer, gar, = misclassified0_15[totalCount]\n",
    "convAnswer = str(answer)\n",
    "stringModel = stringModel + convAnswer\n",
    "def_label = tk.Label(visual_aid_frame, text=stringModel)\n",
    "def_label.pack(padx=10, pady=5, fill=tk.BOTH)\n",
    "\n",
    "#Show number based on user input\n",
    "num_label = tk.Label(number_frame, text=\"What number would you like to see perturbed images of?\")\n",
    "num_label.grid(row=0, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "a = Entry(number_frame, width=50)\n",
    "a.grid(row=1, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "myButton = Button(number_frame, text=\"Click Me!\", pady=50, command=partial(numClick))\n",
    "myButton.grid(row=2, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "\n",
    "# Position image\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tk.IntVar()\n",
    "\n",
    "tk.Radiobutton(input_frame, \n",
    "               text=\"Mixed Examples\",\n",
    "               padx = 20, \n",
    "               variable=v, \n",
    "               value=1).grid(row=2, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "tk.Radiobutton(input_frame, \n",
    "               text=\"Misclassified Examples\",\n",
    "               padx = 20, \n",
    "               variable=v, \n",
    "               value=2).grid(row=2, column=0, sticky=\"nsew\", padx=2, pady=2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7495678a5423b614518f1e7d37edbca4a8c36210f7349cfc3d660176cd54b7f2"
  },
  "kernelspec": {
   "display_name": "Python 3.6.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
