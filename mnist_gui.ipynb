{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import tkinter as tk\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx as onnx\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageTk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pathlib import Path\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex Vogt\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "training_data = torchvision.datasets.MNIST(\n",
    "    '/files/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                              torchvision.transforms.Normalize((0.1307,), (0.3081,))]\n",
    "                                             )\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            ])),\n",
    "        batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, 64, shuffle=True)\n",
    "epochs = 3\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "batch_size = 64\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "pretrained_model = \"model_weights.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
    "use_cuda=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  False\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "# Initialize the network\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(pretrained_model))\n",
    "\n",
    "model2 = Net().to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM attack code\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # Return the perturbed image\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, epsilon):\n",
    "\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    for data, target in test_loader:\n",
    "\n",
    "        # Send the data and label to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        output = model(data)\n",
    "        # get the index of the max log-probability\n",
    "        init_pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # Zero all existing gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Calculate gradients of model in backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect datagrad\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        # Call FGSM Attack\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "\n",
    "        # Re-classify the perturbed image\n",
    "        output = model(perturbed_data)\n",
    "\n",
    "        # Check for success\n",
    "        # get the index of the max log-probability\n",
    "        final_pred = output.max(1, keepdim=True)[1]\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            # Special case for saving 0 epsilon examples\n",
    "            if (epsilon == 0) and (len(adv_examples) < 50):\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append(\n",
    "                    (init_pred.item(), final_pred.item(), adv_ex))\n",
    "        else:\n",
    "            # Save some adv examples for visualization later\n",
    "            if len(adv_examples) < 500:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append(\n",
    "                    (init_pred.item(), final_pred.item(), adv_ex))\n",
    "\n",
    "    # Calculate final accuracy for this epsilon\n",
    "    final_acc = correct/float(len(test_loader))\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon,\n",
    "          correct, len(test_loader), final_acc))\n",
    "\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex Vogt\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0\tTest Accuracy = 9871 / 10000 = 0.9871\n",
      "Epsilon: 0.05\tTest Accuracy = 9410 / 10000 = 0.941\n",
      "Epsilon: 0.1\tTest Accuracy = 8321 / 10000 = 0.8321\n",
      "Epsilon: 0.15\tTest Accuracy = 6446 / 10000 = 0.6446\n",
      "Epsilon: 0.2\tTest Accuracy = 4215 / 10000 = 0.4215\n",
      "Epsilon: 0.25\tTest Accuracy = 2330 / 10000 = 0.233\n",
      "Epsilon: 0.3\tTest Accuracy = 1072 / 10000 = 0.1072\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "model.eval()\n",
    "\n",
    " #Run test for each epsilon\n",
    "for eps in epsilons:\n",
    "    acc, ex = test(model, device, test_loader, eps)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)\n",
    "\n",
    "# epsilon = 0.3\n",
    "# acc, ex = test(model, device, test_loader, eps)\n",
    "# accuracies.append(acc)\n",
    "\n",
    "a, b, c, d, e, f, g = examples;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label, new_label, image, = d[0]\n",
    "plt.title(\"What is this number?\")\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.savefig('saved_figure.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateNewImage(count):\n",
    "    label, new_label, image, = d[count]\n",
    "    plt.title(\"What is this number?\")\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.savefig('saved_figure2.png')\n",
    "    # image1 = Image.open(x)\n",
    "    # test1 = ImageTk.PhotoImage(image1)\n",
    "\n",
    "    # label1.configure(image=test)\n",
    "    # label1.image = test\n",
    "\n",
    "    # Label(root, image=test).pack()\n",
    "\n",
    "    #label1.place(x= 0, y= 0)\n",
    "    # label1.pack()\n",
    "    return label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 200\n",
    "WIDTH = 200\n",
    "IMAGE_HEIGHT = 200\n",
    "IMAGE_WIDTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"/Users/Alex Vogt/Desktop/work-visualization/MNIST_Alex/saved_figure.png\" \n",
    "x2 = \"/Users/Alex Vogt/Desktop/work-visualization/MNIST_Alex/saved_figure2.png\" \n",
    "x3 = \"/Users/Alex Vogt/Desktop/work-visualization/MNIST_Alex/saved_figure3.png\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctCount = 0\n",
    "totalCount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numClick():\n",
    "    currNum = a.get()\n",
    "    temp = 0\n",
    "    # curr = len(d) - 1\n",
    "    curr = 499\n",
    "    images = []\n",
    "    while temp < 6 and curr > 0:\n",
    "        label, new_label, image = d[curr]\n",
    "        if label == int(currNum):\n",
    "            images.append(image)\n",
    "            temp = temp + 1\n",
    "        curr = curr - 1\n",
    "    \n",
    "    for currIterator in range(6):\n",
    "        print(currIterator)\n",
    "        currImage = images[currIterator]\n",
    "        plt.imshow(currImage, cmap=\"gray\")\n",
    "        plt.savefig('saved_figure3.png')\n",
    "\n",
    "        image1 = Image.open(x3)\n",
    "        test = ImageTk.PhotoImage(image1)\n",
    "        label1 = tk.Label(number_frame, image=test)\n",
    "        label1.image = test\n",
    "        if currIterator < 3:\n",
    "            label1.grid(row=3, column=currIterator, sticky=\"nsew\", padx=2, pady=2)\n",
    "        else:\n",
    "            label1.grid(row=4, column=(currIterator - 3), sticky=\"nsew\", padx=2, pady=2)\n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "root = Tk()\n",
    "root.title(\"Human Testing of Adversarial Training\")\n",
    "\n",
    "#Setup frames\n",
    "# global image_frame\n",
    "image_frame = tk.Frame(root, background=\"#FFF0C1\", bd=1, relief=\"sunken\")\n",
    "input_frame = tk.Frame(root, background=\"#D2E2FB\", bd=1, relief=\"sunken\")\n",
    "visual_aid_frame = tk.Frame(root, background=\"#CCE4CA\", bd=1, relief=\"sunken\")\n",
    "output_frame = tk.Frame(root, background=\"#F5C2C1\", bd=1, relief=\"sunken\")\n",
    "number_frame = tk.Frame(root, background=\"#0000FF.\", bd=1, relief=\"sunken\")\n",
    "image_frame.grid(row=0, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "input_frame.grid(row=1, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "visual_aid_frame.grid(row=0, column=1, rowspan=2, sticky=\"nsew\", padx=2, pady=2)\n",
    "output_frame.grid(row=0, column=2, rowspan=2, sticky=\"nsew\", padx=2, pady=2)\n",
    "number_frame.grid(row=0, column=3, rowspan=2, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "\n",
    "\n",
    "root.grid_rowconfigure(0, weight=3)\n",
    "root.grid_rowconfigure(1, weight=2)\n",
    "root.grid_columnconfigure(0, weight=3)\n",
    "root.grid_columnconfigure(1, weight=2)\n",
    "root.grid_columnconfigure(2, weight=2)\n",
    "root.grid_columnconfigure(3, weight=2)\n",
    "\n",
    "\n",
    "# Create a photoimage object of the image in the path\n",
    "image1 = Image.open(x)\n",
    "test = ImageTk.PhotoImage(image1)\n",
    "\n",
    "# label1 = tk.Label(image_frame, image=test)\n",
    "# label1.image = test\n",
    "\n",
    "Label(image_frame, image=test).grid(row=0, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "#label1.place(x= 0, y= 0)\n",
    "#label1.grid(row=0, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "e = Entry(input_frame, width=50)\n",
    "e.grid(row=0, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "\n",
    "#Function for button\n",
    "def myClick():\n",
    "    global totalCount\n",
    "    global label\n",
    "    currCount = correctCount\n",
    "    newLabel = label\n",
    "    currNum = e.get()\n",
    "    print(totalCount)\n",
    "    if (int(currNum) == newLabel):\n",
    "        currCount = currCount + 1\n",
    "        myLabel = Label(output_frame, text=\"Correct!\")\n",
    "        myLabel.grid(row=0, column=2, rowspan=2, sticky=\"nsew\", padx=2, pady=2)\n",
    "    else: \n",
    "        myLabel2 = Label(output_frame, text=\"Incorrect\")\n",
    "        myLabel2.grid(row=0, column=2, rowspan=2, sticky=\"nsew\", padx=2, pady=2)\n",
    "    #Create new image\n",
    "    label = generateNewImage(totalCount)\n",
    "    image1 = Image.open(x2)\n",
    "    test = ImageTk.PhotoImage(image1)\n",
    "    label1 = tk.Label(image_frame, image=test)\n",
    "    label1.image = test\n",
    "    label1.grid(row=0, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "    #Generates new model prediction\n",
    "    stringModel = \"Model Prediction: \"\n",
    "    ga, answer, gar, = d[totalCount]\n",
    "    convAnswer = str(answer)\n",
    "    stringModel = stringModel + convAnswer\n",
    "    def_label = tk.Label(visual_aid_frame, text=stringModel)\n",
    "    def_label.pack(padx=10, pady=5, fill=tk.BOTH)\n",
    "    \n",
    "    #Label(image_frame, image=test).grid(row=1, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "    totalCount = totalCount + 1\n",
    "\n",
    "#Adds a Button\n",
    "myButton = Button(input_frame, text=\"Click Me!\", pady=50, command=partial(myClick))\n",
    "myButton.grid(row=1, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "#Visual Aid\n",
    "stringModel = \"Model Prediction: \"\n",
    "ga, answer, gar, = d[totalCount]\n",
    "convAnswer = str(answer)\n",
    "stringModel = stringModel + convAnswer\n",
    "def_label = tk.Label(visual_aid_frame, text=stringModel)\n",
    "def_label.pack(padx=10, pady=5, fill=tk.BOTH)\n",
    "\n",
    "#Show number based on user input\n",
    "num_label = tk.Label(number_frame, text=\"What number would you like to see perturbed images of?\")\n",
    "num_label.grid(row=0, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "a = Entry(number_frame, width=50)\n",
    "a.grid(row=1, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "myButton = Button(number_frame, text=\"Click Me!\", pady=50, command=partial(numClick))\n",
    "myButton.grid(row=2, column=0, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "\n",
    "# Position image\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7495678a5423b614518f1e7d37edbca4a8c36210f7349cfc3d660176cd54b7f2"
  },
  "kernelspec": {
   "display_name": "Python 3.6.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
